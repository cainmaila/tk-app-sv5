<script lang="ts">
	import { onMount, tick } from 'svelte';
	import { browser } from '$app/environment';
	import type { ChatMessage } from '$lib/types';
	import {
		initializeChatSessionAPI,
		askTokyoExpertAPI,
		getJourneySummaryAPI,
		type ChatSession,
		type JourneySummary
	} from '$lib/services/chatAPI';
	import UserInput from '$lib/components/UserInput.svelte';
	import ChatBubble from '$lib/components/ChatBubble.svelte';
	import LoadingSpinner from '$lib/components/LoadingSpinner.svelte';
	import { APP_TITLE } from '$lib/constants';
	import '../app.css';

	let chatSession: ChatSession | null = $state(null);
	let messages: ChatMessage[] = $state([]);
	let currentQuestion = $state('');
	let isLoading = $state(false);
	let error: string | null = $state(null);
	let chatContainer: HTMLElement;
	let currentAiMessageId: string | null = $state(null);
	let journeySummary: JourneySummary | null = $state(null);

	onMount(async () => {
		if (!browser) return;

		try {
			error = null;
			isLoading = true;

			// ä¸¦è¡Œç²å–èŠå¤©æœƒè©±å’Œè¡Œç¨‹æ‘˜è¦
			const [session, summary] = await Promise.all([
				initializeChatSessionAPI(),
				getJourneySummaryAPI()
			]);

			chatSession = session;
			journeySummary = summary;

			// æ ¹æ“šè¡Œç¨‹æ‘˜è¦ç”Ÿæˆå€‹äººåŒ–çš„æ­¡è¿è¨Šæ¯
			let welcomeMessage = 'æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„æ±äº¬æ—…éŠå°åŠ©æ‰‹ã€‚';

			if (journeySummary) {
				welcomeMessage += `\n\næˆ‘å·²ç¶“äº†è§£æ‚¨çš„è¡Œç¨‹å®‰æ’ï¼š`;

				if (journeySummary.dates.length > 0) {
					welcomeMessage += `\nğŸ“… æ—…éŠæ—¥æœŸï¼š${journeySummary.dates[0]} åˆ° ${journeySummary.dates[journeySummary.dates.length - 1]}`;
				}

				if (journeySummary.hotel) {
					welcomeMessage += `\nğŸ¨ ä½å®¿ï¼š${journeySummary.hotel}`;
				}

				if (journeySummary.dailyPlans.length > 0) {
					welcomeMessage += `\nğŸ“‹ å·²è¦åŠƒ ${journeySummary.dailyPlans.length} å¤©çš„è¡Œç¨‹`;
				}

				welcomeMessage += `\n\næˆ‘å¯ä»¥æ ¹æ“šæ‚¨çš„è¡Œç¨‹å®‰æ’ç‚ºæ‚¨æä¾›ï¼š`;
				welcomeMessage += `\nâ€¢ æ™¯é»é–“çš„äº¤é€šå»ºè­°`;
				welcomeMessage += `\nâ€¢ é™„è¿‘ç¾é£Ÿæ¨è–¦`;
				welcomeMessage += `\nâ€¢ è¡Œç¨‹å„ªåŒ–å»ºè­°`;
				welcomeMessage += `\nâ€¢ è³¼ç‰©å’Œæ–‡åŒ–é«”é©—æ¨è–¦`;
			} else {
				welcomeMessage +=
					'è«‹å•æœ‰ä»€éº¼å¯ä»¥ç‚ºæ‚¨æœå‹™çš„å—ï¼Ÿä¾‹å¦‚ï¼šæ¨è–¦æ–°å®¿çš„ç¾é£Ÿã€æŸ¥è©¢æ˜å¤©æ·ºè‰å¯ºçš„é–‹æ”¾æ™‚é–“ï¼Œæˆ–æ˜¯å¹«æ‚¨è¦åŠƒä¸€æ—¥éŠè¡Œç¨‹ã€‚';
			}

			welcomeMessage += `\n\nè«‹éš¨æ™‚å‘Šè¨´æˆ‘æ‚¨æƒ³äº†è§£ä»€éº¼ï¼`;

			messages = [
				{
					id: Date.now().toString(),
					role: 'model',
					text: welcomeMessage
				}
			];
		} catch (e) {
			console.error('åˆå§‹åŒ–èŠå¤©å¤±æ•—:', e);
			error = e instanceof Error ? e.message : 'åˆå§‹åŒ–èŠå¤©æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ã€‚';
		} finally {
			isLoading = false;
		}
	});

	$effect(() => {
		if (chatContainer && messages.length > 0) {
			// Scroll to bottom with a slight delay to allow DOM update for streaming text
			setTimeout(() => {
				if (chatContainer) {
					chatContainer.scrollTop = chatContainer.scrollHeight;
				}
			}, 100);
		}
	});

	const handleSubmitQuestion = async () => {
		if (!currentQuestion.trim() || isLoading || !chatSession) return;

		const questionToAsk = currentQuestion.trim();
		const userMessage: ChatMessage = {
			id: Date.now().toString(),
			role: 'user',
			text: questionToAsk
		};

		const aiMessageId = `ai-${Date.now()}`;
		currentAiMessageId = aiMessageId;

		const aiPlaceholderMessage: ChatMessage = {
			id: aiMessageId,
			role: 'model',
			text: '', // Initially empty for streaming
			sources: []
		};

		messages = [...messages, userMessage, aiPlaceholderMessage];
		currentQuestion = '';
		isLoading = true;
		error = null;

		try {
			await askTokyoExpertAPI(
				chatSession,
				questionToAsk,
				(textChunk) => {
					// onChunk
					messages = messages.map((msg) =>
						msg.id === currentAiMessageId ? { ...msg, text: msg.text + textChunk } : msg
					);
				},
				(sources) => {
					// onComplete
					messages = messages.map((msg) =>
						msg.id === currentAiMessageId ? { ...msg, sources: sources || [] } : msg
					);
					isLoading = false;
					currentAiMessageId = null;
				},
				(streamError) => {
					// onError callback from askTokyoExpertAPI (errors during stream)
					console.error('Streaming error reported to App:', streamError);
					error = streamError.message; // Show global error

					messages = messages.map((msg) => {
						if (msg.id === currentAiMessageId) {
							const errorNotice = ` [æœå‹™è¨Šæ¯ï¼š${streamError.message}]`;
							return { ...msg, text: (msg.text || '') + errorNotice };
						}
						return msg;
					});
					isLoading = false;
					currentAiMessageId = null;
				}
			);
		} catch (e) {
			// This catch is for errors setting up the stream, not during it (e.g. immediate throw from askTokyoExpert before stream starts)
			console.error('è©¢å• Gemini API å¤±æ•— (setup phase):', e);
			const errorMessage = e instanceof Error ? e.message : 'èˆ‡ AI æºé€šæ™‚ç™¼ç”Ÿå•Ÿå‹•éŒ¯èª¤ã€‚';
			error = errorMessage;
			// Remove the AI placeholder if setup failed, and add a specific error message from model
			const filteredMessages = messages.filter((msg) => msg.id !== aiMessageId);
			messages = [
				...filteredMessages,
				{
					id: (Date.now() + 2).toString(),
					role: 'model',
					text: `æŠ±æ­‰ï¼Œç„¡æ³•é–‹å§‹èˆ‡AIæºé€šï¼š${errorMessage}`
				}
			];
			isLoading = false;
			currentAiMessageId = null;
		}
	};

	const handleInputChange = (value: string) => {
		currentQuestion = value;
	};
</script>

<svelte:head>
	<title>{APP_TITLE}</title>
	<meta name="description" content="å°ˆç‚ºå°ç£æ—…å®¢è¨­è¨ˆçš„æ±äº¬æ—…éŠAIå¤¥ä¼´" />
</svelte:head>

<div
	class="flex flex-col"
	style="height: 100vh; max-width: 48rem; margin: 0 auto; background-color: white; box-shadow: 0 20px 25px -5px rgba(0, 0, 0, 0.1), 0 10px 10px -5px rgba(0, 0, 0, 0.04);"
>
	<header
		style="background: linear-gradient(to right, #0ea5e9, #4f46e5); color: white; padding: 1rem; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);"
	>
		<div class="flex items-center justify-between mb-2">
			<h1 class="text-2xl font-bold">{APP_TITLE}</h1>
			<a
				href="/summary"
				class="bg-white bg-opacity-20 hover:bg-opacity-30 px-3 py-1 rounded-lg text-sm transition-colors backdrop-blur-sm"
			>
				ğŸ“‹ è¡Œç¨‹æ‘˜è¦
			</a>
		</div>
		<p class="text-sm text-center" style="color: #bae6fd;">å°ˆç‚ºå°ç£æ—…å®¢è¨­è¨ˆçš„æ±äº¬æ—…éŠAIå¤¥ä¼´</p>
	</header>

	{#if error}
		<div class="error" role="alert">
			<p class="font-bold">éŒ¯èª¤</p>
			<p>{error}</p>
		</div>
	{/if}

	<main
		bind:this={chatContainer}
		class="flex-1"
		style="overflow-y: auto; padding: 1.5rem; background-color: #f8fafc;"
	>
		<div class="space-y-4">
			{#each messages as message (message.id)}
				<ChatBubble {message} />
			{/each}
			<!-- This spinner indicates AI is working after user sends a message, before AI bubble streams -->
			{#if isLoading && messages.length > 0 && messages[messages.length - 1].role === 'model' && messages[messages.length - 1].text === '' && currentAiMessageId === messages[messages.length - 1].id}
				<div class="flex" style="justify-content: flex-start;">
					<div
						class="flex items-center space-x-2"
						style="background-color: #e5e7eb; color: #374151; padding: 0.75rem; border-radius: 0.5rem; box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1); max-width: 36rem;"
					>
						<LoadingSpinner />
						<span>AI æ­£åœ¨æº–å‚™å›è¦†...</span>
					</div>
				</div>
			{/if}
		</div>
	</main>

	<!-- Initial loading spinner for app init -->
	{#if isLoading && messages.length === 0 && !error}
		<div
			class="flex-1 flex flex-col justify-center items-center"
			style="padding: 1.5rem; background-color: #f8fafc;"
		>
			<div class="space-y-4 text-center">
				<LoadingSpinner size="large" />
				<p class="text-slate-600">æ­£åœ¨åˆå§‹åŒ–AIå°åŠ©æ‰‹...</p>
			</div>
		</div>
	{/if}

	<footer style="padding: 1rem; background-color: #f1f5f9; border-top: 1px solid #cbd5e1;">
		<UserInput
			bind:value={currentQuestion}
			onChange={handleInputChange}
			onSubmit={handleSubmitQuestion}
			isLoading={isLoading || !chatSession}
		/>
	</footer>
</div>
